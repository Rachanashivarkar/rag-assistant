RAG Assistant (Local AI Document Chatbot)
ğŸ“˜ Overview

RAG Assistant is a Retrieval-Augmented Generation (RAG) based chatbot built using LangChain.
It allows users to upload and query their own text documents.
Unlike typical implementations that require an OpenAI API key, this project uses Hugging Face local embeddings (all-MiniLM-L6-v2) â€” making it completely free and offline.

ğŸš€ Features

âœ… Load and process any text document (.txt)
âœ… Use local Sentence-BERT embeddings for semantic search
âœ… Ask natural language questions about document content
âœ… Works offline â€” no API keys or internet required
âœ… Lightweight, clean, and beginner-friendly Python setup

ğŸ—ï¸ Tech Stack
Component	Technology Used
Programming Language	Python 3.10+
Framework	LangChain
Embeddings	HuggingFace Sentence-BERT (all-MiniLM-L6-v2)
Vector Database	ChromaDB
Model	Local Retrieval QA Chain
Interface	Command-Line Interface (CLI)
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/rag-assistant.git
cd rag-assistant

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
venv\Scripts\activate    # On Windows
# OR
source venv/bin/activate # On Mac/Linux

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


(If you donâ€™t have a requirements.txt, you can manually install them)

pip install langchain langchain-community langchain-core langchain-openai chromadb sentence-transformers

ğŸ§© Project Structure
rag-assistant/
â”‚
â”œâ”€â”€ app.py                # Main Python file (RAG chatbot logic)
â”œâ”€â”€ documents/            # Folder containing your text files
â”œâ”€â”€ requirements.txt       # Dependencies list
â””â”€â”€ README.md              # Project description

ğŸ§  How It Works

The program loads your .txt documents using LangChain TextLoader.

It converts the text into embeddings using Sentence-BERT from HuggingFace.

These embeddings are stored in a Chroma vector database for similarity search.

When you ask a question, it retrieves the most relevant chunks and generates a contextual answer.

â–¶ï¸ Running the Project

Run this command in your terminal:

python app.py


Youâ€™ll see:

ğŸ¤– AI Assistant is ready (free local mode)! Type 'exit' to quit.

You:


Type your questions, for example:

You: What is this document about?


The assistant will respond based on your document content.

ğŸ‘©â€ğŸ’» Author

Rachana Shivarkar
ğŸ“ Computer Engineering Student
ğŸ’¡ Passionate about AI, Machine Learning, and Software Development

ğŸ“œ License

This project is licensed under the MIT License â€” free to use and modify.